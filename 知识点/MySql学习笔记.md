#一.基本知识
- 数据库是文件的集合，是依照某种数据模型组织起来并存放与二级存储器中的数据集合；数据库实例是程序，是位于用户与操作系统之间的一层数据管理软件，用户对数据库的任何操作，包括数据库定义、数据查询等都是在数据库实例下运行的，应用程序只有通过数据库实例才能和数据库打交道
##1.1.连接MySQL
###1.1.1.TCP/IP
###1.1.2.命名管道和共享内存
###1.1.3.UNIX域套接字


#二.InnoDB
##2.1.体系架构
- 拥有多个内存块，这些内存块组成一个大的内存池
	- 维护所有进程、线程需要访问的多个内部数据结构
	- 缓存磁盘上的数据，方便快速读取，同时在对磁盘文件的数据修改之前在这里缓存
	- 重做日志缓冲

###2.1.1.后台线程：刷新内存池中的数据，保证缓冲池中的内存缓存的是最近的数据；将以修改的数据文件刷新到磁盘文件，同时保证在数据库发生异常的情况下InnoDB能恢复到正常运行状态

- Master Thread:主要负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性，包括脏页的刷新。合并插入缓冲，UNDO页的回收
- IO Thread:write、read、insert buffer和log thread
- Purge Thread:回收已经使用并分配的undo页
- Page Cleaner Thread：将之前版本中脏页的刷新操作都放入到单独的线程中完成
###2.1.2.内存
- 缓冲池：基于磁盘存储的，并将其中的记录按照页的方式进行管理；页从缓冲池刷新回磁盘的操作并不是在每次页发生更新时触发，而是通过Checkpoint的机制刷新回磁盘（索引页、数据页、undo页、插入缓冲、自适应哈希索引、InnoDB存储的锁信息、数据字典信息）
- 重做日志缓冲
- 额外的内存池

##2.2.Checkpoint技术
- 缩短数据库的恢复时间
- 缓冲池不够用时，将脏页刷新到磁盘
- 重做日志不可用时，刷新脏页
##2.3.关键特性
- 插入缓冲
- 两次写
- 自适应哈希索引
- 异步IO
- 刷新邻接页







#一.基本知识
##1.组成：连接池组件；管理服务和工具组件；SQL接口组件；查询分析器组件；优化器组件；缓冲组件；插件式存储引擎；物理文件
##2.存储引擎是基于表的，而不是数据库
##3.通配符（1.%（任意字符出现任意次数）；2._单个字符）
##4.拼接字段Concat()函数
##5.WHERE在数据分组前进行过滤，HAVING在数据分组后进行过滤
##6.SELECT子句顺序（SELECT; FROM; WHERE; GROUP BY; HAVING; ORDER BY; LIMIT）
##7.子查询；相关子查询
##8.联结表
##9.自联结与子查询
##10.组合查询（在单个查询中从不同的表返回类似结构的数据；对单个表执行多个查询，按单个查返回结果）
##11.全文本搜索
##12.对UPDATE或DELETE使用WHERE子句前，应该先用SELECT进行测试，保证过滤的是正确的结果
##13.视图
##14.存储过程（1.把处理封装在容易使用的单元中，简化复杂的操作；2.不要求反复建立一系列的处理步骤，保证数据的完整性；3.简化对变动的管理；4.提高性能；5.高性能）
##15.使用游标：
##16.使用触发器：
##17.事务管理：
##18.权限管理：
##19.数据类型：
##20.索引建立（1.仅当出现清晰需求的时候才添加索引；2.装载数据前删除索引，然后在仓库开放营业前重建他们；3.主键和外键键索引，还有被频繁检索的列）
##21.聚集索引与非聚集索引
###21.1.1.聚集索引就是以主键创建的索引
###21.1.2.非聚集索引就是以非主键创建的索引
- 聚集索引在叶子节点存储的是表中的数据
- 非聚集索引在叶子节点存储的是主键和索引列
- 使用非聚集索引查询出数据时，拿到叶子上的主键再去查到想要查找的数据。(拿到主键再查找这个过程叫做回表)
##22.最左匹配原则
- 索引可以简单如一个列(a)，也可以复杂如多个列(a, b, c, d)，即联合索引。
- 如果是联合索引，那么key也由多个列组成，同时，索引只能用于查找key是否存在（相等），遇到范围查询(>、<、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找。
- 因此，列的排列顺序决定了可命中索引的列数。


#二.详解
##2.1.数据类型：
###2.1.1.数字数据类型：1）INT:可以指定多达11位的宽度;2)TINYINT:可以指定多达4位数的宽度;3)可以指定最多5位的宽度;4)MEDIUMINT:可以指定最多9位的宽度;5)BIGINT:可以指定最多20位的宽度;6) FLOAT(M,D):可以定义显示长度(M)和小数位数(D);7)DOUBLE(M,D) ;8)DECIMAL(M,D);
###2.1.2.日期和时间类型:1)DATE： 以YYYY-MM-DD格式的日期，在1000-01-01和9999-12-31之间；2）DATETIME：日期和时间组合以YYYY-MM-DD HH:MM:SS格式，在1000-01-01 00:00:00 到9999-12-31 23:59:59之间；3）TIME：存储时间在HH:MM:SS格式；4）YEAR(M)：以2位或4位数字格式来存储年份；
###3.字符串类型：1）CHAR(M):固定长度的字符串是以长度为1到255之间个字符长度;2)VARCHAR(M)：可变长度的字符串是以长度为1到255之间字符数,必须定义长度。3）BLOB or TEXT：字段的最大长度是65535个字符。BLOB是“二进制大对象”，并用来存储大的二进制数据，如图像或其他类型的文件。定义为TEXT文本字段还持有大量的数据; 两者之间的区别是，排序和比较上存储的数据，BLOB大小写敏感，而TEXT字段不区分大小写。4）TINYBLOB 或 TINYTEXT：BLOB或TEXT列用255个字符的最大长度。5）MEDIUMBLOB or MEDIUMTEXT：BLOB或TEXT列具有16777215字符的最大长度；6）LONGBLOB 或 LONGTEXT：LOB或TEXT列具有4294967295字符的最大长度；7）ENUM:枚举



##2.2.SELECT语法：
`
	SELECT 
    	column_1, column_2, ...
	FROM
    	table_1
	[INNER | LEFT |RIGHT] JOIN table_2 ON conditions
	WHERE
    	conditions
	GROUP BY column_1
	HAVING group_conditions
	ORDER BY column_1
	LIMIT offset, length;
`
###2.2.1.WHERE过滤结果集中的行
###2.2.2.GROUP BY将一组行组合成小分组，并对每个小分组应用聚合函数
###2.2.3.HAVING过滤器基于GROUP BY子句定义的小分组



##2.3.INSERT语法：
    INSERT INTO table(column1,column2...) VALUES (value1,value2,...);
##2.4.UPDATE语法：
    UPDATE [LOW_PRIORITY] [IGNORE] table_name 
	SET 
    	column_name1 = expr1,
    	column_name2 = expr2,
    	...
	WHERE
    	condition;
##2.5.DELETE语法：
    DELETE FROM table_name
	WHERE condition;

#三.原理
##3.1.B树
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/B-tree%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B.png)
##3.1.B+树
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/B%2Btree%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B.png)
###3.1.1.只有最底层的节点（叶子节点）才保存信息（相关表的行位置）
###3.1.2.其它节点只是在搜索中用来指引到正确节点的。
###3.1.3.最底层的节点是跟后续节点相连接的
##3.2.索引
###3.2.1.不要使用太多索引，插入/更新/删除表中的一个行的操作（log(N)）；增加索引意味着给事务管理器带来更多的工作负荷
##3.3.核心组件：
###3.3.1.进程管理器（process manager）：很多数据库具备一个需要妥善管理的进程/线程池。
###3.3.2.网络管理器（network manager）：网路I/O是个大问题，尤其是对于分布式数据库。
###3.3.3.文件系统管理器（File system manager）：磁盘I/O是数据库的首要瓶颈。
###3.3.4.内存管理器（memory manager）：为了避免磁盘I/O带来的性能损失，需要大量的内存。
###3.3.5.安全管理器（Security Manager）：用于对用户的验证和授权。
###3.3.6.客户端管理器（Client manager）：用于管理客户端连接。
##3.4.工具
###3.4.1.备份管理器（Backup manager）：用于保存和恢复数据。
###3.4.2.复原管理器（Recovery manager）：用于崩溃后重启数据库到一个一致状态。
###3.4.3.监控管理器（Monitor manager）：用于记录数据库活动信息和提供监控数据库的工具。
###3.4.4.Administration管理器（Administration manager）：用于保存元数据（比如表的名称和结构），提供管理数据库、模式、表空间的工具。
##3.5.查询管理器：
###3.5.1.查询解析器（Query parser）：用于检查查询是否合法
###3.5.2.查询重写器（Query rewriter）：用于预优化查询
###3.5.3.查询优化器（Query optimizer）：用于优化查询
###3.5.4.查询执行器（Query executor）：用于编译和执行查询
##3.6.数据管理器
###3.6.1.事务管理器（Tra****nsaction manager）：用于处理事务
###3.6.2.缓存管理器（Cache manager）：数据被使用之前置于内存，或者数据写入磁盘之前置于内存
###3.6.3.数据访问管理器（Data access manager）：访问磁盘中的数据
##3.7.事务的ACID
###3.7.1.原子性（Atomic）:数据库事务是不可分割的工作单位
###3.7.2.一致性（Consistency）：指数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性
###3.7.3.隔离性（Isolation）：指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间
###3.7.4.持久性：指的是只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态

##3.8.数据库的隔离级别：
###3.8.1.读未提交（Read uncommitted）：出现脏读情况；两个并发的事务，事务B读取了事务A尚未提交的数据
###3.8.2.读提交（Read committed ）：出现不可重复读；两个并发的事务，事务A事先读取了数据，事务B紧接着更新了数据，并提交了事务，而事务A再次读取该数据时，数据已经发生了改变
###3.8.3.重复读（Repeatable read）：出现幻读；
###3.8.4.序列化（Serializable）


#四.InnoDB技术原理详解
##4.1.体系架构
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/InnoDB%E4%BD%93%E7%B3%BB%E6%9E%B6%E6%9E%84.png)
##4.2.后台线程：多线程模型，负责处理不同的任务
###4.2.1.Master Thread:负责将缓冲池中的数据异步刷新到磁盘，保证数据的一致性
###4.2.2.IO Thread:使用了AIO来处理写IO请求，IO Thread主要负责这些IO请求的回调处理
###4.2.3.Purge Thread:回收已经使用并分配的undo页
###4.2.4.Page Cleaner Thread:脏页的刷新操作放到单独的线程完成
##4.3.内存：基于磁盘存储的，并将其中的记录按照页的方式进行管理
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/InnoDB%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E5%AF%B9%E8%B1%A1.png)
###4.3.1.缓冲池：
###4.3.2.LRU List,Free List和Flush List:管理内存区域
###4.3.3.重做日志缓冲：
###4.3.4.额外的内存池：对内存的管理通过一种称为内存堆的方式进行，对一些数据结构本身的内存进行分配时，需要从额外的内存池中进行申请，当该区域的内存不够时，会从缓冲池中进行申请。
##4.4.Checkpoint技术：
###4.4.1.针对的问题：1）缩短数据库的恢复时间；2）缓冲池不够用时，将脏页刷新到磁盘；3）重做日志不可用时，刷新脏页
###4.4.2.Sharp Checkpoint/Fuzzy Checkpoint:
##4.5.Master Thread:
##4.6.关键特性：
###4.6.1.插入缓冲：对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入，若不在，则先放入到一个Insert Buffer对象中（1）条件：1）索引是辅助索引；2）索引不是唯一的
###4.6.2.两次写（部分写导致失效）：保证数据页的可靠性
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E4%B8%A4%E6%AC%A1%E5%86%99%E6%9E%B6%E6%9E%84.png)
###4.6.3.自适应哈希索引：自动根据访问的频率与模式来自动的为某些热点页建立哈希索引
###4.6.4.异步IO
###4.6.5.刷新邻接页：对于传统的机械硬盘建议开启该项功能，对于固态硬盘有着超高的IOPS性能的磁盘，建议将该参数设置为0，即关闭该特性
##4.7.InnoDB页结构
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/InnoDB%E9%A1%B5%E7%BB%93%E6%9E%84.png)
###4.7.1.各个数据页可以组成一个双向链表
###4.7.2.每个数据页中的记录可以组成一个单向链表

#五.文件
##5.1.参数文件：告诉MySQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小设置，还会介绍各种参数的类型
- 动态参数
- 静态参数

##5.2.日志文件（错误日志；二进制日志；慢查询日志；查询日志）
##5.3.套接字文件
##5.4.pid文件：
##5.5.表结构定义文件
##5.6.InnoDB存储引擎文件
###5.6.1.表空间文件：
###5.6.2.重做日志文件

#六.表
##6.1.逻辑存储结构：
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/InnoDB%E9%80%BB%E8%BE%91%E5%AD%98%E5%82%A8%E7%BB%93%E6%9E%84.png)
###6.1.1.表空间：存放的只是数据、索引和插入缓冲Bitmap页，其他类的数据还是存放在原来的共享表空间内
###6.1.2.段：数据段；索引段；回滚段
###6.1.3.区：有连续页组成，在任何情况下每个区大小都为1MB
###6.1.4.页：磁盘管理的最小单位
###6.1.5.行：行记录格式（Compact/Redundant）

##6.2.数据页结构：
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E6%95%B0%E6%8D%AE%E9%A1%B5%E7%BB%93%E6%9E%84.png)
##6.3.约束：
##6.4.视图（被用作一个抽象装置，对于一些应用程序，程序本身不需要关心基表的结构，只需要按照视图定义来取数据或更新数据）：命名的虚表，视图中的数据没有实际的物理存储
##6.5.分区表：（RANGE分区；LIST分区；HASH分区；KEY分区）

#七.索引与算法
##7.1.B+树索引（页分裂，页合并）
###7.1.1.聚集索引：按照每张表的主键构造一课B+树，同时叶子节点中存放的即为整张表的行记录数据，将聚集索引的叶子节点称为数据页；每张表只能拥有一个聚集索引
###7.1.2.非聚集索引：叶子节点并不包含行记录的全部数据，叶子节点除了包含键值外，每个叶子节点中的索引行还包含一个书签，该书签告诉InnoDB哪里可以找到与索引相对应的行数据
> 当通过辅助索引来寻找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后通过主键索引来找到完整的行记录

##7.1.3.联合索引
###7.1.4.覆盖索引


##7.2.Cardinality值（索引中不重复记录数量的预估值）
##7.3.哈希算法
##7.4.全文检索
###7.4.1.倒排索引：


#八.锁
##8.1.lock与latch的区别
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/Lock%E4%B8%8Elatch%E7%9A%84%E5%8C%BA%E5%88%AB.png)
##8.2.锁类型：行级锁（共享锁；排它锁）
##8.3.锁算法：（Record Lock/Gap Lock/Next-Key Lock）
##8.4.锁问题（脏读；不可重复读；丢失更新）
##8.5.阻塞：
##8.6.死锁：（1）超时机制；2）wait-for graph死锁检测机制）
##8.7.锁升级

#九.事务
##9.1.分类
- 扁平事务
- 带有保存点的扁平事务
	- 保存点：用来通知系统应该记住事务当前的状态，以便发生错误后，事务能够回到保存点当时的状态 ；易失的，而非持久的
- 链事务
- 嵌套事务
- 分布式事务






##9.1.事务的实现
###9.1.1.redo log（保证事务的原子性和持久性）：通常是物理日志，记录的是页的物理修改操作
###9.1.2.undo log(保证事务的一致性)：逻辑日志，根据每行记录进行记录
##9.2.事务控制语句
##9.3.事务操作的统计
###9.3.1.每秒请求数（QPS）
###9.3.2.每秒事务处理的能力（TPS）
##9.4.分布式事务：使用分布式事务时，InnoDB的事务隔离级别必须设置为SERIALIZABLE
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E6%A8%A1%E5%9E%8B.png)
##9.5.不好的事务习惯：
###9.5.1.在循环中提交
###9.5.2.使用自动提交
###9.5.3.使用自动回滚
##9.6.长事务：通过小批量事务处理机制来解决长事务带来的问题
#十.备份与恢复[https://www.jianshu.com/p/e276ad5165b6](https://www.jianshu.com/p/e276ad5165b6)
##10.1.备份的分类：
###10.1.1.备份方法（热备；冷备；温备）
###10.1.2.备份后的文件内容（逻辑备份；裸文件备份）
###10.1.3.备份数据库的内容（完全备份；增量备份；日志备份）
##10.2.复制：
###10.2.1.步骤：1）主服务器把数据更改记录到二进制日志中；2）从服务器把主服务器的二进制日志复制到自己的中继日志中；3）从服务器重做中继日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性
![](https://i.imgur.com/ocGyxki.png)
![](https://i.imgur.com/9qtRPDW.png)


#十一.性能调优：[https://www.jianshu.com/p/fb1c16777851](https://www.jianshu.com/p/fb1c16777851 "数据库调优策略")
##11.1.数据库的应用类型
- OLTP(在线事务处理)：多用在日常的事务处理应用中。如银行交易、在线商品交易。数据库的容量较小；IO密集型
- OLAP(在线分析处理)：多用在数据仓库或数据集市中，一般需要执行复杂的SQL语句来进行查询；CPU密集型






##11.1.RAID(独立磁盘冗余数组)
###11.1.1.作用：1）增强数据的集成度；2）增强容错功能；3）增加处理量或容量
##11.2.[http://www.hack520.com/169.html](http://www.hack520.com/169.html "RAID")
##11.3.MySQL查询过程
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B.png)
##11.4.数据库优化维度
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BC%98%E5%8C%96%E7%BB%B4%E5%BA%A6.png)
#注意事项
###1.存储引擎是基于表的，而不是数据库
###2.约束更是一个逻辑的概念，用来保证数据的完整性，而索引是一个数据结构，既有逻辑上的概念，在数据库中还代表着物理存储的方式
###3.数据库的应用分类：1）OLTP(在线事务处理)；2）OLAP(在线分析处理)
###4.B+树索引能找到的只是被查找数据行所在的页，然后数据库通过把页读入到内存，再在内存中进行查找，最后得到要查找的数据

#十二.基本架构
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/MySQL%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84.png)
##12.1.查询流程
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/MySQL%E6%9F%A5%E8%AF%A2%E8%BF%87%E7%A8%8B.png)

#十三.基本知识
##13.1.索引的目的：在大数据量的查询中提升查询速度,避免全表扫描
##13.2.什么样的信息可以成为索引：过滤性好的字段
##13.3.密集索引与稀疏索引的区别
###13.3.1.密集索引文件中的每个搜索码值都对应一个索引值
###13.3.2.稀疏索引文件只为索引码的某些值建立索引项
###13.3.3.innodb是密集索引,MyIsam是稀疏索引

#十四.补充知识点
##14.1.覆盖索引
- 
##14.2.最左匹配原则

##14.3.回表
- 从普通索引查出主键索引，然后查询出数据的过程称为回表

#十五.索引
##15.2.实现上
- 聚集索引
- 非聚集索引
##15.1.功能上：
- 普通索引：最基本的索引，没有任何约束
- 唯一索引：与普通索引类似，但具有唯一性约束
- 主键索引：特殊的唯一索引，不允许有空值
- 复合索引：将多个列组合在一起创建索引，可以覆盖多个列
- 外键索引：只有InnoDB类型的表才可以使用外键索引，保证数据的一致性、完整性和实现级联操作
- 全文索引：MySQL自带的全文索引只能用于InnoDB、MyISAM,并且只能对英文进行全文索引
- 索引的设计
	- MySql 的主键不能太大，如果使用 UUID 这种，将会浪费 B+ 树的非叶子节点
	- MySql 的主键最好是自增的，如果使用 UUID 这种，每次插入都会调整 B+树，从而导致页分裂，严重影响性能

#十六.锁
##16.1.类型维度
- 共享锁（读锁 / S 锁）
- 排它锁（写锁 / X 锁）
- 悲观锁
- 乐观锁（使用版本号字段，类似 CAS 机制，即用户自己控制。缺点：并发很高的时候，多了很多无用的重试）
##16.2.锁的粒度
- 表锁
- 页锁
- 行锁

#十七.MVCC:多版本并发控制
- 同一份数据临时保留多版本的方式，实现并发控制
- MVCC在大多数情况下代替了行锁，实现了对读的非阻塞，读不加锁，读写不冲突。缺点是每行记录都需要额外的存储空间，需要做更多的行维护和检查工作
- READ COMMITTED 和 REPEATABLE READ 两个隔离级别下工作
###实现
- 时间戳（TS）+递增的事务ID(T)



#注意点
##不同日志的特点

- 重做日志：对于InnoDB有一个重做日志缓存

> 作用：确保事务的持久性。redo日志记录事务执行后的状态，用来恢复未写入data file的已成功事务更新的数据，防止事务发生故障的时间点，尚有脏页未写入磁盘，在重启MySQL服务的时候，根据redo log进行重做，从而达到事务的持久性
> 
> 内容：物理格式的日志，记录的是物理数据页面的修改信息，其redo log是顺序写入redo log file的物理文件中去的
> 
> 什么时候产生：事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中
> 
> 什么时候释放：当对应事务的脏页写入磁盘之后，redo log的使命也就完成了，重做日志占用的空间就可以重用

- 回滚日志

> 作用：保证数据的原子性，保存了事务发生前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC）,即非锁定读
> 
> 内容：逻辑格式的日志，在执行undo的时候，仅仅是将数据从逻辑上恢复至事务之前的状态，而不是从屋里页面上操作实现的
> 
> 什么时候产生：事务开始之前，将当前的版本生成undo log，undo也会产生redo来保证undo log 的可靠性
> 
> 什么时候释放：事务提交之后，undo log并不能立马释放，而好似放入带清理的链表，有purge线程判断是否由其他事务在使用undo段中表的上一个事务之前的版本信息，决定是否可以清理undo log 的日志空间
> 
> 对应物理文件：共享表空间；独立undo表空间

- 二进制日志

> 作用：用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步；用于数据库的基于时间点的还原
> 
> 内容：逻辑格式的日志
> 
> 什么时候产生：事务提交的时候，一次性将事务中的sql语句按照一定的格式记录到binlog中
> 
> 什么时候释放：binlog的默认保持时间由参数expire_logs_days配置，也就是说对于非活动日志文件，在生成时间超过expire_logs_days配置的天数后，会被自动删除

##MySQL中的锁机制
- 概述
	- MyISAM支持表锁，InnoDB支持表锁和行锁，默认为行锁
	- 表级锁（表共享读锁；表独占写锁）：开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发量最低
	- 行级锁（共享锁；排它锁）：开销大，加锁慢，会出现死锁，锁粒度小，发生锁冲突的概率小，并发度最高 

- 什么时候使用表锁：
	- 事务需要更新表的大部分数据
	- 事务涉及多个表，比较复杂 

- 两段锁
	- 一个加锁原则，一种协议
	- 锁操作分为两个阶段，加锁阶段只加锁不放锁，解锁阶段只放锁不加锁
	- 比如一个事务中两个update语句，此时执行完第一个update不会立即放锁，等加锁阶段完成后再放锁
	- 事务开始后就处于加锁阶段，一直到执行ROLLBACK和COMMIT之前都是加锁阶段。ROLLBACK和COMMIT使事务进入解锁阶段 


#补充
-  长连接：连接成功后，客户端持续请求，则一直使用同一个连接，但其会引发MySQL内存涨的特别快，因为MySQL在执行过程中临时使用的内存是管理在连接对象里的，这些资源会在断开连接才释放
	-  定期断开长连接
	-  如果使用MySQL5.7或更新版本，可以通过执行mysql_reset_connection来重新初始化连接资源，这个过程不需要使用重连和重新做权限验证，但是会将连接恢复到刚刚创建完成时的状态

##1.WAL(Write-Ahead Logging)：先写日志，再写磁盘
###1.1.1.日志
- redo log
- binlog
> redo log 和binlog都是顺序写，磁盘的顺序写比随机写速度快
> 
> 组提交机制，可以大幅度降低磁盘的IOPS消耗
##1.长事务
- 避免长事务对业务的影响
	-  set autocommit=1
	-  commit work and chain

##2.索引
- 索引的常见模型
	- 哈希表：等值查询比较好，区间查询较慢
	- 有序数组：等值查询和范围查询较好，插入数据成本太高，之适用于静态存储引擎
	- 搜索树

> 主键索引（聚簇索引）：叶子节点存储的是整行数据
> 非主键索引:叶子节点存储的是主键的值(需要回表的过程)
 
- 覆盖索引能够减少数的搜索次数
- 最左前缀原则
- 索引下推

- 普通索引和唯一索引：两者查询能力上差别不大，主要是更新性能的影响
- change buffer
- redo log主要节省的是随机写磁盘的IO消耗（转成顺序写），而change buffer主要节省的则是随机读磁盘的IO消耗

>change buffer对更新过程有加速作用，只限于用在普通索引中，而不适用于唯一索引
>
>merge的时候是真正进行数据更新的时刻，而change buffer的主要目的就是将记录的变更动作缓存下来，所以在一个数据页做merge之前，change buffer记录的变更越多，收益越大
>
>对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较少，此时效果最好；而对于业务更新模式是写入后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程，这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价
- 表中插入新纪录（4,400）过程
	- 记录要更新的目标也在内存中
		- 对于唯一索引，找到3和5之间的位置，判断没有冲突，插入这个值，语句执行结束
		- 对于普通索引，找到3和5之前的位置，插入这个值，语句执行结束
	- 记录要更新的目标页不在内存中
		- 对于唯一索引来说，需要将数据页读入内存中，判断到没有冲突，插入这个值，语句执行结束
		- 对于普通索引来说，则是将更新记录在change buffer，语句执行结束   

- 前缀索引：定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本；建立索引时关注区分度，区分度越高越好；使用前缀索引就用不上覆盖索引对查询性能的优化
	- 倒序存储
	- 使用hash字段

- 选择索引（扫描行数，临时表，是否排序等）
	- 扫描行数如何判断（根据统计信息估算记录数，这个统计信息就是索引的“区分度”；一个索引上不同值的个数称为“基数”）
	-  
- 索引选择异常和处理（analyze table）
	- 采用force index强行选择一个索引 
	- 修改语句，引导MySQL使用我们期望的索引
	- 新建一个更合适的索引，来提供给优化器选择，或删掉误用的索引
- 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能







##3.锁
- 全局锁：典型应用场景时全库逻辑备份（Flush tables with read lock），逻辑备份
- 表级锁：（lock tables ... read/write）
	- 表锁
	- 元数据锁 ：不需要显示使用，在访问一个表示被自动加上。其作用时保证读写的正确性
> 事务中的MDL锁，在语句执行开始是申请，语句结束后不会马上释放，而是等到整个事务提交后在释放

- 如何安全的给小表加字段
	- 首先解决长事务
	- alter table语句中设置等待时间，在指定的时间能够拿到MDL写锁最好，拿不到不要阻塞后面的业务语句先放弃，有开发人员或者DBA通过重试命令重复这个过程 

- 行锁：InnoDB事务中，行锁在需要的时候加上，但并不是不需要就立刻释放，而是要等事务结束时才释放。两阶段锁协议（如果事务中需要锁多个行，把最可能造成锁冲突、最可能影响并发度的锁尽量往后放）

- 死锁
	- 直接进入等待，直到超时，超时时间可以通过参数innodb_lock_wait_timeout设置
	- 发起死锁检测，发现死锁后，主动回滚死锁链条中的某个事务，让其他事务继续执行，将参数innodb_deadlock_detect设置为on表示开启这个逻辑


- 如何解决热点行更新导致的性能问题：问题的症结在死锁检测消耗大量的CPU资源
	- 确保业务不会出现死锁，临时将死锁检测关闭
	- 控制并发度（中间件实现，修改源码）

- 加锁规则
	- 加锁的基本单位是next-key lock
	- 查询过程中访问到的对象才会加锁
	- 索引上的等值查询，给唯一索引加锁的时候，next-key lock退化为行锁
	- 索引上的等值查询，向右遍历时且最后一个值不满足等值条件时，next-key lock退化为间隙锁
	- 唯一索引上的范围查询会访问到不满足条件的第一个值为止

##4.事务
- 两个“视图”：没有物理结构，作用是执行期间用来定义“我能看到什么数据”
	- 一个是view。查询语句定义的虚拟表，在调用的时候执行查询语句并生成结果。创建视图的语法是create view...,而他的查询方法和表一样
	- InnoDB在实现MVCC时用到的一致性读视图即consistent read view，用于支持RC和RR隔离级别的实现

- 隔离性。实现上，数据库里面会创建一个视图，访问的时候以视图逻辑结果为准。在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。在“读”提交隔离级别下：这个视图是在每个SQL语句开始执行的时候创建的；“读未提交”隔离级别下直接返回记录上的最新值，没有视图的概念；“串行化”隔离级别下直接加锁的方式来避免并行访问

##5.脏页 
- 刷脏页的策略
	- 脏页比例
	- redo log写盘速度

![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/InnoDB%E8%84%8F%E9%A1%B5%E9%80%9F%E5%BA%A6%E7%AD%96%E7%95%A5.png)

- InnoDB用缓冲池管理内存

> 一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长
> 
> 日志写满，更新全部堵住，写性能跌为0



##6.空间回收
> InnoDB表包含两部分，即：表结构定义和数据

-  表数据既可以存放在共享表空间里，也可以是单独的文件，这个行为有参数innodb_file_per_table控制
	- 这个参数设置为OFF表示标的数据放在系统共享表空间，也就是和数据字典放在一起
	- 这个参数设置为ON表示，每个InnoDB表数据存储在一个以.idb为后缀的文件中，建议设置为ON  

- delete命令是将数据页标记为可复用。但在磁盘上文件不会变小，因此删除数据汇造成空洞，插入数据也会。经过大量增删改的表，都可能存在空洞，如果把这些空洞去掉，就能够收缩表空间
- 重建表流程
	- 建立一个临时文件，扫描表A主键的所有数据页
	- 用数据页表A的记录生成B+树，存储在临时文件中
	- 生成临时文件的过程中，将所有对A的操作记录在一个日志文件中，对应的图是state2的状态
	- 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个数据上和表A相同的数据文件，对应图中的state3的状态
	- 用临时文件替换表A的数据文件
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/Online%20DDL.png)  
##7.排序
> sort_buffer


- 全字段排序(内存中排序；磁盘临时文件辅助排序)
- rowid排序
	 - 如果MySQL实在当心排序内存太小，会影响排序效率，才会使用rowid排序
	 - 如果MySQL认为内存足够大，会优先选择全字段排序 
- 通过建立联合索引等可以消减排序过程
- 随机排序

##8.查询长期不返回结果
- 等MDL锁：找到谁持有MDL写锁，将其kill掉
- 等flush:
- 等行锁

##8.数据可靠性
- binlog的写入机制：事务执行过程中，先把日志写到binlog cache,事务提交的时候，再把binlog cache写到binlog文件中；一个事务的binlog不能拆开；每个线程有自己的binlog cache，但是公用一份binlog

![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/binlog%E5%86%99%E7%9B%98%E7%8A%B6%E6%80%81.png)
	- write和fsync的时机，由参数sync_binlog控制
		- sync_binlog=0的时候，表示每次提交事务都只write，不fsync
		- sync_binlog=1的时候，表示每次提交事务都fsync
		- sync_binlog=N(N>1)时候，表示每次提交事务都write，但累计N个事务后才fsync  
> 出现IO瓶颈时，将sync_binlog设置成一个比较大的值，可以提升性能，在实际场景中，需要考虑丢失日志量的可控性，主机发生异常重启时，会丢失最近N个事务的binlog日志

- redo log写入机制
 ![](https://github.com/HelloWucq/working-knowledge-point/blob/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/MySQL%20redo%20log%E5%AD%98%E5%82%A8%E7%8A%B6%E6%80%81.png)
	- redo log buffer中，物理上是在MySQL进程内存中
	- 写到磁盘，但没有持久化，物理上式文件系统的page cache里面
	- 持久化到磁盘中 

	- 为了控制redo log的写入策略，InnoDB提供了innodb_flush_log_at_trx_commit参数
		- 设置为0时，表示每次事务提交都只是把redo log留在redo log buffer中
		- 设置为1时，表示每次事务提交都将redo log直接持久化磁盘中
		- 设置为2时，表示每次事务提交时都是吧redo log写到page cache  
	
	- 组提交 

- 崩溃恢复的判断规则
	- 如果redo log里面的事务是完整的，也就是已经有了commit标识，则直接提交
	- 如果redo log里面的事务只有完整的prepare，则判断对应的事务binlog是否存在并完整
		- 如果是，则提交事务
		- 否则，回滚事务 
- MySQL性能瓶颈，而且出现在IO上
	- 设置binlog_group_commit_sync_delay和binlog_group_commit_sync_no_delay_count参数，减少binlog写盘次数
	- 将sync_binlog设置大于1的值，风险是主机掉电时会丢binlog
	- 将innodb_flush_log_at_trx_commit设置为2.主机掉电时会丢数据 



##9.“饮鸩止渴”提高性能
- 短连接风暴
	- 先处理掉那些占着连接但是不工作的线程（有损的）
	- 减小连接过程的消耗 

- 慢查询
	- 索引没有设计好
	- SQL语句没有写好
	- MySQL选错索引 

- QPS突增



##9.主备一致
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E4%B8%BB%E5%A4%87%E6%B5%81%E7%A8%8B%E5%9B%BE.png)


- binlog三种格式
	- statement:
	- row:
	- mixed :

- 循环复制问题
##10.高可用
- 主备延迟（备库消费中转日志的速度比主库生产binlog的速度要慢）
	- 备库所在机器的性能比主库的机器性能差 （对称部署）
	- 备库的压力大（一主多从；通过binlog输出到外部系统）
	- 大事务
	- 大表DDL（计划内的DDL，建议使用gh-ost方案）
	- 备库的并行复制能力
- 主备切换
	- 可靠性优先策略 
	- 可用性优先策略（可能出现数据不一致的情况）
- 多线程复制
	- 按表分发策略
	- 按行分发策略 
-  coordinatior分发
	- 不能造成更新覆盖
	- 同一个事务不能被拆开  

- 一主多从，主库发生故障，主备切换结果
	- 基于位点的主备切换（找同步点） 
	- GTID（全局事务ID）

- 如何检测数据库是否出现问题
	-  select(1)
	-  查表判断
	-  更新判断
	-  内部统计



##11.读写分离
- 架构
	- 客户端直连 
	- 带proxy的架构


- 处理过期读
	- 强制走主库方案
	- sleep方案
	- 判断主备无延迟方案
	- 配合semi-sync方案
	- 等主库位点方案
	- 等GTID方案



##12.误删数据
> 恢复数据比较安全的做法，是恢复一个备份，或者找一个从库作为临时库，在临时库上执行这些操作，然后在将确认过的临时库的数据，恢复回主库


- 误删行
- 误删表/库：全量备份+增量日志
- 延迟复制备库
- 预防误删库、表
	- 账号分离
	- 制定操作规范，这样做的目的，是避免写错要删除的表明 
- rm删除数据

#13.kill
> kill并不是马上停止，而是告诉执行线程说，这条语句已经不需要继续执行了，可以开始“执行停止逻辑了”。发送kill命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被kill的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的

- kill无效的情况
	-  线程没有执行到判断线程状态的逻辑
	-  终止逻辑耗时过长

> **MySQL是“边读边发的”**


- LRU算法
	- 新数据插入到链表头部
	- 每当缓存命中（即缓存数据被访问），则将数据移到链表头部
	- 当链表满的时候，将链表尾部的数据丢弃 


##13.join
- Index Nested-Loop Join(NLJ)
- Simple Nested-Loop Join
- Block Nested-Loop Join(BNL)
	- 可能会多次扫描被驱动表，占用磁盘IO资源
	- 判断join条件需要执行M*N次对比，如果是大表就会占用非常多的CPU资源
	- 可能会导致Buffer Pool的热数据被淘汰，影响内存命中率 
- Multi-Range Read优化（MRR）:尽量使用顺序读盘
	- read_rnd_buffer 
- 临时表
	- 建表语法是create temporary tabel ...
	- 一个临时表只能能创建它的session访问，对其他线程不可见，在这个session结束时，会自动删除临时表
	- 临时表可以与普通版同名
	- show tables命令不显示临时表

- 内存临时表（union；group by等场合），磁盘临时表
	- 语句执行过程可以一边读过程，一边直接得到结果，是不需要额外内存的，否则就需要额外的内存，来保存中间结果
	- join_buffer是无序数组，sort_buffer是有序数组，临时表的二维结构
	- 如果执行逻辑需要用到二维表特性，就会优先考虑使用临时表 
-  group by优化方法
	- 索引
	- 直接排序  
- 内存表：使用Memory引擎的表，这种表的数据保存在内存中
- 扩展-hash join

- Batched Key Access
- 如何选择驱动表
	- 使用小表驱动大表 

- InnoDB与Memory引擎的数据组织方式不同
	- InnoDB引擎把数据放在主键索引，其他索引上保存的是主键id。索引组织表
	- Memory引擎采用的是把数据单独存放，索引上保存数据位置的数据组织形式，堆组织表

#14.自增主键
- 自增值修改机制


#15.最快复制一张表
- mysqldump
 
	mysqldump -h$host -P$port -u$user --add-locks=0 --no-create-info --single-transaction  --set-gtid-purged=OFF db1 t --where="a>900" --result-file=/client_tmp/t.sql
- 导出CSV文件
	- 这条语句会将结果保存在服务端
	- into outfile指定文件的生成位置，这个位置必须受参数secure_file_priv的限制。参数secure_file_priv的可选值和作用
		- 如果设置为empty,表示不限制文件生成的位置
		- 吐过设置为一个表示路径的字符串，要求生成的文件只能放在这个指定的目录，或其子目录
		- 如果设置为NULL，表示禁止这个MySQL实例上执行select ... into outfile操作
	- 这条命令不会帮你覆盖文件，因此需要确保/server_temp/t.csv文件不存在，否则会报错
	- 这条命令生成的文本文件中，原则上一个数据行对应文本文件的一行，但是，如果字段中包含换行符，在生成的文本中也会有换行符

- 物理拷贝方法
	










