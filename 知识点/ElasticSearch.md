#一.基础介绍及索引原理分析（[https://www.cnblogs.com/dreamroute/p/8484457.html](https://www.cnblogs.com/dreamroute/p/8484457.html)）
##1.1.基本概念
- ElasticSearch是面向文档的，意味着它存储整个对象或文档，不仅存储文档，而且索引每个文档的内容使其可以被检索

#二.原理介绍

#三.集群内的原理
##3.1.空集群
- 一个运行中的 Elasticsearch 实例称为一个 节点，而集群是由一个或者多个拥有相同 cluster.name 配置的节点组成， 它们共同承担数据和负载的压力。
- 当一个节点被选举成为 主 节点时， 它将负责管理集群范围内的所有变更，例如增加、删除索引，或者增加、删除节点等。 而主节点并不需要涉及到文档级别的变更和搜索等操作，所以当集群只拥有一个主节点的情况下，即使流量的增加它也不会成为瓶颈。 任何节点都可以成为主节点。我们的示例集群就只有一个节点，所以它同时也成为了主节点。
##3.2.集群健康
###status字段
- green:所有的主分片和副本分片都正常运行。 
- yellow:所有的主分片都正常运行，但不是所有的副本分片都正常运行。 
- red:有主分片没能正常运行。 
##3.3.添加索引
###索引：指向一个或者多个物理分片的逻辑命名空间


- 一分片是一个底层的工作单元，仅保存了全部数据中的一部分
- 分片将数据分发到集群内各处。分片是数据的容器，文档保存在分片内，分片有被分配在集群内的各个节点里，Elasticsearch会自动在各节点中迁移分片
-  一个分片可以是 主 分片或者 副本 分片。 索引内任意一个文档都归属于一个主分片，所以主分片的数目决定着索引能够保存的最大数据量。
##3.4.故障转移
##3.5.水平扩容以及数据保障
#四.文档
- 最顶层或者根对象, 这个根对象被序列化成 JSON 并存储到 Elasticsearch 中，指定了唯一 ID。
##4.1.文档元数据
- _index：文档在哪存放
- _type:文档表示的对象类别
- _id:文档唯一标识
##4.2.文档的增删改查
##4.3.处理冲突：乐观并发控制
- version版本控制
##4.4.批量获取

#五.分布式文档存储
##5.1.路由一个文档到一个分片中
    shard = hash(routing) % number_of_primary_shards
- 建索引的时候就确定好主分片的数量 并且永远不会改变这个数量：因为如果数量变化了，那么所有之前路由的值都会无效，文档也再也找不到了。
##5.2.主分片和副本分片如何交互
- 我们可以发送请求到集群中的任一节点。 每个节点都有能力处理任意请求。 每个节点都知道集群中任一文档位置，所以可以直接将请求转发到需要的节点上
##5.3.新建、索引和删除单个文档
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E6%96%B0%E5%BB%BA%E3%80%81%E7%B4%A2%E5%BC%95%E5%92%8C%E5%88%A0%E9%99%A4%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png)
- 客户端向 Node 1 发送新建、索引或者删除请求。 
- 节点使用文档的 _id 确定文档属于分片 0 。请求会被转发到 Node 3，因为分片 0 的主分片目前被分配在 Node 3 上。 
- Node 3 在主分片上面执行请求。如果成功了，它将请求并行转发到 Node 1 和 Node 2 的副本分片上。一旦所有的副本分片都报告成功, Node 3 将向协调节点报告成功，协调节点向客户端报告成功。
##5.4.取回单个文档
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E5%8F%96%E5%9B%9E%E5%8D%95%E4%B8%AA%E6%96%87%E6%A1%A3.png)
- 客户端向 Node 1 发送获取请求。
- 节点使用文档的 _id 来确定文档属于分片 0 。分片 0 的副本分片存在于所有的三个节点上。 在这种情况下，它将请求转发到 Node 2 。
- Node 2 将文档返回给 Node 1 ，然后将文档返回给客户端。
##5.5.局部更新文档
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E5%B1%80%E9%83%A8%E6%9B%B4%E6%96%B0%E6%96%87%E6%A1%A3.png)
- 客户端向 Node 1 发送更新请求
- 它将请求转发到主分片所在的 Node 3 。 
- Node 3 从主分片检索文档，修改 _source 字段中的 JSON ，并且尝试重新索引主分片的文档。 如果文档已经被另一个进程修改，它会重试步骤 3 ，超过 retry_on_conflict 次后放弃。 
- 如果 Node 3 成功地更新文档，它将新版本的文档并行转发到 Node 1 和 Node 2 上的副本分片，重新建立索引。 一旦所有副本分片都返回成功， Node 3 向协调节点也返回成功，协调节点向客户端返回成功。
##5.6.多文档模式
###5.6.1.使用 mget 取回多个文档
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E4%BD%BF%E7%94%A8mget%E5%8F%96%E5%9B%9E%E5%A4%9A%E4%B8%AA%E6%96%87%E6%A1%A3.png)
- 客户端向 Node 1 发送 mget 请求。 
- Node 1 为每个分片构建多文档获取请求，然后并行转发这些请求到托管在每个所需的主分片或者副本分片的节点上。一旦收到所有答复， Node 1 构建响应并将其返回给客户端。
###5.6.2.使用 bulk 修改多个文档
![](https://github.com/HelloWucq/working-knowledge-point/raw/master/%E5%AD%A6%E4%B9%A0%E5%9B%BE%E7%89%87/%E4%BD%BF%E7%94%A8%20bulk%20%E4%BF%AE%E6%94%B9%E5%A4%9A%E4%B8%AA%E6%96%87%E6%A1%A3.png)
- 客户端向 Node 1 发送 bulk 请求。
- Node 1 为每个节点创建一个批量请求，并将这些请求并行转发到每个包含主分片的节点主机。
- 主分片一个接一个按顺序执行每个操作。当每个操作成功时，主分片并行转发新文档（或删除）到副本分片，然后执行下一个操作。 一旦所有的副本分片报告所有操作成功，该节点将向协调节点报告成功，协调节点将这些响应收集整理并返回给客户端。
#六.搜索
##6.1.空搜索



#七.映射与分析
##7.1.精确值VS全文
##7.2.倒排索引
##7.3.分析与分析器
- 字符过滤器
- 分词器
- Token过滤器
##7.4.映射
###核心简单域
- 字符串: string
- 整数 : byte, short, integer, long
- 浮点数: float, double
- 布尔型: boolean
- 日期: date
###自定义域映射
- 全文字符串域和精确值字符串域的区别 
- 使用特定语言分析器 
- 优化域以适应部分匹配 
- 指定自定义数据格式 
- 还有更多 
##7.5.查询表达式
##7.6.重要的查询
- match_all查询
- match查询
- multi_match查询
- range查询
- term查询：精确值匹配
- exists查询和missing查询




#八.排序与相关性
##8.1.相关性
##8.2.相似度算法：检索词频率/反向文档频率，TF/IDF
- 检索词频率
- 反向文档频率
- 字段长度准则

#九.分布式检索

#十.索引管理
##10.1.创建一个索引
##10.2.删除一个索引
##10.3.索引设置
- number_of_shards:每个索引的主分片数，默认值是 5 。这个配置在索引创建后不能修改。 
- number_of_replicas:每个主分片的副本数，默认值是 1 。对于活动的索引库，这个配置可以随时修改。
##10.4.配置分析器
##10.5.创建自定义分析器
##10.6.类型与映射
##10.7.根对象
- 一个 properties 节点，列出了文档中可能包含的每个字段的映射 
- 各种元数据字段，它们都以一个下划线开头，例如 _type 、 _id 和 _source
- 设置项，控制如何动态处理新的字段，例如 analyzer 、 dynamic_date_formats 和 dynamic_templates
- 其他设置，可以同时应用在根对象和其他 object 类型的字段上，例如 enabled 、 dynamic 和 include_in_all
##10.8.动态映射

#十一.分片内部原理
##11.1.文本可被搜索：倒排索引（不可变性）
##11.2.动态更新索引：用更多的索引
##11.3.进实时搜索
##11.4.持久化变更
##11.5.段合并

#十二.结构化搜索
##12.1.精确值查询
##12.2.组合过滤器
##12.3.查找多个精确值
##12.4.范围
##12.5.NUll值
##12.6.缓存

#十三.全文搜索

#十四.相关度
##14.1.相关度评分：布尔模型、词频/逆向文档频率（TF/IDF）、向量空间模型












#十五.聚合
##15.1.桶（Buckets）：满足特定条件的文档的集合
##15.2.指标（Metrics）:对桶内的文档进行统计计算
##15.3.过滤和聚合
##15.4.近似聚合
###15.4.1.三角因子模型：大数据、精确性和实时性
- 精确 + 实时：数据可以存入单台机器的内存之中，我们可以随心所欲，使用任何想用的算法。结果会 100% 精确，响应会相对快速。 
- 大数据 + 精确 ：传统的 Hadoop。可以处理 PB 级的数据并且为我们提供精确的答案，但它可能需要几周的时间才能为我们提供这个答案。
- 大数据 + 实时：近似算法为我们提供准确但不精确的结果
###近似聚合（cardinality度量）：HyperLogLog++算法
-可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）
- 小的数据集精度是非常高的。 
- 我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关。 
###percentiles百分位数度量：TDigest算法
- 百分位的准确度与百分位的 极端程度 相关，也就是说 1 或 99 的百分位要比 50 百分位要准确。这只是数据结构内部机制的一种特性，但这是一个好的特性，因为多数人只关心极端的百分位。
- 对于数值集合较小的情况，百分位非常准确。如果数据集足够小，百分位可能 100% 精确。
- 随着桶里数值的增长，算法会开始对百分位进行估算。它能有效在准确度和内存节省之间做出权衡。 不准确的程度比较难以总结，因为它依赖于 聚合时数据的分布以及数据量的大小

##15.5.Doc Values：序列化的列式存储
- DocValues是在索引时与倒排索引同时生成的，并且是不可变的。与倒排一样，保存在lucene文件中（序列化到磁盘）。 
- DocValues使用列式压缩 
- DocValues支持禁用 
##15.6.Fielddata
###doc values 不生成分析的字符串，然而，这些字段仍然可以使用聚合，是因为使用了fielddata 的数据结构。与 doc values 不同，fielddata 构建和管理 100% 在内存中，常驻于 JVM 内存堆。fielddata 是 所有 字段的默认设置
- Fielddata 是延迟加载的。如果你从来没有聚合一个分析字符串，就不会加载 fielddata 到内存中，是在查询时候构建的。
- fielddata 是基于字段加载的， 只有很活跃地使用字段才会增加fielddata 的负担。
- fielddata 会加载索引中（针对该特定字段的） 所有的文档，而不管查询是否命中。逻辑是这样：如果查询会访问文档 X、Y 和 Z，那很有可能会在下一个查询中访问其他文档。 
- 如果空间不足，使用最久未使用（LRU）算法移除fielddata。 






#十六.地理位置
- 不管字符串形式还是数组形式，都是经度在前，纬度在后。

#十七.数据建模
##17.1.关联关系处理：Elasticsearch是扁平化的。索引是独立文档的集合体。 文档是否匹配搜索请求取决于它是否包含所有的所需信息。
##17.2.嵌套对象
##17.3.父子对象


#十八.扩容设计
##18.1.分片预分配
##18.2.海量分片
###分片的代价
- 一个分片的底层即为一个 Lucene 索引，会消耗一定文件句柄、内存、以及 CPU 运转。 
- 每一个搜索请求都需要命中索引中的每一个分片，如果每一个分片都处于不同的节点还好， 但如果多个分片都需要在同一个节点上竞争使用相同的资源就有些糟糕了
- 用于计算相关度的词项统计信息是基于分片的。如果有许多分片，每一个都只有很少的数据会导致很低的相关度。 
##18.3.容量规划
- 基于你准备用于生产环境的硬件创建一个拥有单个节点的集群
- 创建一个和你准备用于生产环境相同配置和分析器的索引，但让它只有一个主分片无副本分片
- 索引实际的文档（或者尽可能接近实际）
- 运行实际的查询和聚合（或者尽可能接近实际）


##18.4.副本分片

##18.5.多索引
###你需要在不停服务的情况下增加容量时，下面有一些有用的建议
- 创建一个新的索引来存储新的数据。 
- 同时搜索两个索引来获取新数据和旧数据。 
##18.6.扩容不是无限的
###集群状态
- 集群级别的设置 
- 集群中的节点 
- 索引以及它们的设置、映射、分析器、预热器（Warmers）和别名
- 与每个索引关联的分片以及它们分配到的节点 




#十九.管理、监控和部署
##19.1.监控
###19.1.1.Marvel监控
###19.1.2.集群健康
###19.1.3.监控单个节点（JVM）
###19.1.4.集群统计
###19.1.5.索引统计

##19.2.部署

